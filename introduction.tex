The algorithmic study of cuts and flows is one of the pillars of combinatorial optimization. The foundations of this field were established 
in the celebrated work of Ford and Fulkerson in the mid-50s~\cite{FordF56}. They studied the $s-t$ edge connectivity problem, namely finding a set of edges of minimum weight whose removal disconnects two vertices $s$ from $t$ in a graph (such a set of edges is called an $s-t$ mincut). They showed that the weight of an $s-t$ mincut equals the maximum flow between $s$ and $t$ in the graph, a duality that has underpinned much of the success in this field. Soon after their work, in a remarkable result, Gomory and Hu~\cite{GomoryH61} showed that by using just $n-1$ maxflows, they could construct a tree $T$ on the vertices of an undirected graph $G$ such that for every pair of vertices $s$ and $t$, the $s-t$ edge connectivity in $T$ was equal to that in $G$. In other words, the $n\choose 2$ pairs of vertices had at most $n-1$ different edge connectivities and they could be obtained using just $n-1$ maxflow calls. Moreover, for all vertex pairs $s$ and $t$, the bipartition of vertices in the $s-t$ mincut in tree $T$ (note that this is just the bipartition created by removing the minimum weight edge on the unique $s-t$ path in $T$) was also an $s-t$ mincut in graph $G$. This data structure, called a {\em cut tree} or more appropriately a {\em Gomory-Hu tree} (abbreviated GH-tree) after its creators, has become a standard feature in algorithms textbooks, courses, and research since their work.

But, rather surprisingly, in spite of the remarkable successes in this field as a whole, the best algorithm for constructing a GH-tree remains the one given by Gomory and Hu almost six decades after their work. There have been alternatives suggested along the way, although none of them unconditionally improves on the original construction. Gusfield~\cite{Gusfield90} gave an algorithm that also uses $n-1$ maxflows, but on the original graph itself (the GH algorithm runs maxflows on contracted graphs as we will see later) to improve the performance of the algorithm in practice. Bhalgat~{\em et al.}~\cite{BhalgatHKP08} (see also \cite{HariharanKP07}) obtained an $\tO(mn)$ algorithm for this problem, but only for unweighted graphs. (Note that using the state of the art maxflow algorithms~\cite{liu2020faster}, the GH algorithm has a running time of $m^{4/3+o(1)}n$ for unweighted graphs, which is slower.) Karger and Levine~\cite{KargerL15} matched this running time using a randomized maxflow subroutine, also for unweighted graphs. Recently, Abboud~{\em et al.}~\cite{AbboudKT20a} improved this bound for {\em sparse} unweighted graphs to $\tO(m^{3/2}n^{1/6})$, thereby demonstrating that the $\tO(mn)$ is not tight, at least in certain edge density regimes. Further improvements have been obtained in special cases: in particular, near-linear time algorithms are known for planar graphs~\cite{BorradaileSW15} and surface-embedded graphs~\cite{BorradaileENW16}. Experimental studies of GH tree algorithms have also been performed~\cite{GoldbergT01}. The reader is referred to a survey article on this topic for more background~\cite{Panigrahi16}.

In spite of all the works described above, the status of the GH tree problem for general weighted graphs has remained unchanged for the last six decades. Namely, we know that a GH tree can be constructed using $n-1$ maxflows, but no better. In fact, surprisingly, a faster GH tree algorithm is not known {\em even if one allowed approximations}, i.e., if the $s-t$ mincuts in the GH tree and those in the original graph could differ by a multiplicative factor. At first glance, this would appear surprising, since $\tO(m)$-time algorithms for  $(1+\e)$-approximation of maxflows are known. (In contrast, obtaining an exact maxflow algorithm that runs in near-linear time remains one of the major open challenges in graph algorithms.) But, the difficulty in using these faster approximate maxflow algorithms in the GH tree problem is that the GH algorithm (and also Gusfield's algorithm) use recursive calls in a manner that approximation errors can build up across the different recursive layers of the algorithm. Approximation, however, does present some advantage, in that one can use standard graph sparsification techniques to reduce the number of edges to $\tO(n)$ (see, e.g., \cite{BenczurK15,FungHHP19}) and then apply the GH algorithm (with exact maxflow) on this sparse graph. This reduces the running time to $n-1$ invocations of maxflow on $\tO(n)$-edge graphs, which has a total running time of $\tO(n^{5/2})$ using the current state of the art maxflow algorithm of Lee and Sidford~\cite{LeeSflow}. But, fundamentally, even allowing approximations, we do not have a GH tree algorithm that beats the $O(n)$ maxflows benchmark set by the original GH algorithm.

But, there has been some exciting progress of late in this line of research. Very recently, in a beautiful paper, Abboud~{\em et al.}~\cite{AbboudKT20b} showed that the problem of finding all pairs edge connectivities (that a GH tree obtains) can be reduced to $\polylog(n)$ instances of the single source mincut problem (we call this the \ssc problem). Given a fixed source vertex $s$, the latter problem asks for the $s-t$ edge connectivity of $s$ with every other vertex $t$. Their reduction is also robust to approximations because, crucially, the recursive depth of the reduction is only $\polylog(n)$ (as against the recursive depth of GH and Gusfield's algorithms, which can be $\Omega(n)$). So, in essence, they reduced the recursive depth of the algorithm in exchange for using a more powerful primitive, namely edge connectivity for $n-1$ pairs of vertices (one of the pair is common) rather than for just a single pair. The algorithm that they used to solve the single source edge connectivity problem is the obvious one: run $s-t$ maxflow for every vertex $t$. Naturally, this does not improve the running time for exact all pairs edge connectivity, since we are still running $n-1$ maxflows. But, importantly, if approximations are allowed, we can now use the $\tO(m)$-time approximate maxflow algorithm rather than the exact one. Coupled with sparsification, this yields a running time bound of $\tO(n^2)$ improving on the previous bound of $\tO(n^{5/2})$. 

However, while this improves the time complexity of approximate all pairs edge connectivity, the reduction framework of \cite{AbboudKT20b} does not support the construction of an approximate GH tree. Namely, they give a data structure (called a {\em flow tree}) that returns the (approximate) edge connectivity of a vertex pair when queried, but does not return a mincut for that pair. Nevertheless, this result creates a range of possibilities, now that we have a technique for designing computation trees for all pairs edge connectivity that have small recursive depth. In this paper, we give the first approximation algorithm (our approximation factor is $1+\e$ for any $\e>0$) for GH tree that beats the running time of $n-1$ maxflow calls. Namely, we show that a $(1+\e)$-approximate GH-tree can be constructed using polylog number of calls to an exact maxflow subroutine, plus $\tO(m)$ time outside these maxflow calls.

\subsection{Our Results}

%\alert{DP: Should we formally define the problem statements here?} \textcolor{blue}{JL: not sure, since the notation for approx GH tree is a bit cumbersome. Maybe just say "see Definition XX for the formal def for approx GH tree"?}

To state our main result, we first formally define an approximate GH tree. 

\BD[Approximate Gomory-Hu tree]
Given a graph $G=(V,E)$, a $(1+\e)$-approximate Gomory-Hu tree is a weighted tree $T$ on $V$ such that
 \BI
 \im For all $s,t\in V$, consider the minimum-weight edge $(u,v)$ on the unique $s-t$ path in $T$. Let $U'$ be the vertices of the connected component of $T-(u,v)$ containing $s$.
Then, the set $U'\s V$ is a $(1+\e)$-approximate $(s,t)$-mincut, and its value is the weight of the $(u, v)$ edge in $T$.
 \EI
\ED

We now state our main theorem that obtains a $(1+\e)$-approximate GH tree for weighted graphs:
\begin{restatable}{theorem}{ApproxW}\thml{approx-w}
    Let $G$ be an undirected graph with non-negative edge weights. There is a randomized algorithm that w.h.p., outputs a $(1+\e)$-approximate Gomory-Hu tree and runs in $\tO(m)$ time plus calls to exact max-flow on instances with a total of $\tO(n\e\inv\log^2\De)$ vertices and $\tO(n\e\inv\log^2\De)$ edges, where $\De$ is the ratio of maximum to minimum edge weights. Assuming polynomially bounded edge weights and using the $\tO(m\sqrt{n})$ time max-flow algorithm of Lee and Sidford~\cite{LeeSflow}, the algorithm runs in $\tO(m + n^{3/2}\e^{-2})$ time.
\end{restatable}
For unweighted graphs, we obtain the following result, which gives a better running time for sparse graphs (if $m = o(n^{9/8})$):
\begin{restatable}{theorem}{ApproxU}\thml{approx-u}
Let $G$ be an unweighted, undirected graph. There is a randomized algorithm that w.h.p., outputs a $(1+\e)$-approximate Gomory-Hu Steiner tree and runs in $\tO(m)$ time plus calls to exact max-flow on unweighted instances with a total of $\tO(n\e\inv)$ vertices and $\tO(m\e\inv)$ edges. Using the $m^{4/3+o(1)}$-time max-flow algorithm for unweighted graphs of Liu and Sidford~\cite{liu2020faster}, the algorithm runs in $m^{4/3+o(1)}\e\inv$ time.
\end{restatable}

To the best of our knowledge, this is the first algorithm for (approximate) GH tree that goes beyond $n-1$ maxflow calls in general weighted graphs. Our reduction to exact maxflow instances is ``black box'', i.e., any maxflow algorithm can be used; as a consequence, if one were to assume that eventually maxflow would be solved in $\tO(m)$-time, as is often conjectured, then these theorems would automatically yield an $\tO(m)$-time algorithm for a $(1+\e)$-approximate GH tree.

Given these results, one might be tempted to replace the exact maxflow calls in our algorithm by approximate maxflow subroutines. Indeed, if this were possible, the running time of the overall algorithm would be $\tO(m)$ without additional assumptions (i.e., without assuming a $\tO(m)$-time exact maxflow algorithm). Unfortunately, a key tool that we employ called the {\em isolating cuts lemma}, which was recently introduced by the authors for the deterministic mincut problem~\cite{LiP20}, requires the computation of exact maxflows; we are not aware of any approximation versions of this lemma. We leave the problem of obtaining a near-linear time approximate GH tree algorithm as an interesting open question (that is probably easier than an exact $\tO(m)$-time maxflow algorithm).


Abboud~{\em et al.}~\cite{AbboudKT20b} recently considered the \apc (also called {\em flow tree}) problem, which asks for the value of the $s-t$ mincut for all vertex pairs $s, t$ but not a mincut itself. 

\BD[All-pairs min-cut]
In the \emph{all-pairs min-cut} (\apc) problem, the input is an undirected graph $G=(V,E)$ and we need to output a data structure that allows us to query the value of the $(s,t)$-mincut for each pair $s, t\in V$. In the \emph{$(1+\e)$-approximate \apc} problem, the input is the same, and we need to output a $(1+\e)$-approximation to the value of the $(s,v)$-mincut for each $v\in V\sm \{s\}$.
\ED

Abboud~{\em et al.} gave a framework that reduces the \apc problem to $\polylog(n)$ calls to the single source mincut (\ssc) problem.

\BD[Single-source min-cut]
In the \emph{single-source min-cut} (\ssc) problem, the input is an undirected graph $G=(V,E)$ and a source vertex $s\in V$, and we need to output a $(s,v)$-mincut for each $v\in V\sm \{s\}$. In the \emph{$(1+\e)$-approximate \ssc} problem, the input is the same, and we need to output a $(1+\e)$-approximate $(s,v)$-mincut for each $v\in V\sm \{s\}$.
\ED

To solve the \ssc instances, Abboud {\em et al.} used $n-1$ maxflows. Our work shows that the \ssc problem can be approximately solved using $\polylog(n)$ maxflows calls, and that an approximate GH tree can be recovered in the process. Our main tool is the following subroutine that we call the {\em Cut Threshold} (\ct) problem, %\alert{better name?}, 
which may have further applications on its own:

\begin{restatable}[Cut Threshold algorithm]{theorem}{Thr}\thml{thr}
Let $G=(V,E)$ be a weighted, undirected graph, and let $s\in V$, and let $\la\ge0$ be a parameter (the ``cut threshold"). There is an algorithm that outputs whp all vertices $v\in V$ with $\mincut(s,v)\le\la$, and runs in $\tO(m)$ time plus $\pl(n)$ calls to max-flow instances on $O(n)$-vertex, $O(m)$-edge graphs.
\end{restatable}

We use this theorem to obtain an algorithm for approximately solving the \ssc problem that is faster than running approximate maxflows for all the $n-1$ vertices separately:

\begin{restatable}{theorem}{SSMC}\thml{ssmc}
Let $G$ be a weighted, undirected graph, and let $s\in V$. There is an algorithm that outputs, for each vertex $v\in V\sm\{s\}$, a $(1+\e)$-approximation of $\mincut(s,v)$, and runs in $\tO(m\log\De)$ time plus $\pl(n)\cdot \log\De$ calls to max-flow on $O(n)$-vertex, $O(m)$-edge graphs, where $\De$ is the ratio of maximum to minimum edge weights.
\end{restatable}

Finally, note that a (approximate) GH tree also solves the (approximate) \apc problem. But, we can also get an \apc algorithm by simply plugging in the \ssc algorithm in \thm{ssmc} to the reduction framework of Abboud {\em et al.} This improves the time complexity of the \apc problem from $\tO(mn)$ obtained by  Abboud {\em et al.}~\cite{AbboudKT20b} to $\tO(m + n^{3/2})$.

%\textcolor{blue}{JL: should mention more work to be done to get GH tree}

\subsection{Our Techniques}

To sketch our main ideas, let us first think of the \ct problem (\thm{thr}). Note that this theorem is already sufficient to obtain the improved the running times for the \ssc and \apc problems, although obtaining a $(1+\e)$-approximate GH tree needs additional ideas. To solve the \ct problem, our main tool is the {\em isolating cuts lemma}, introduced by the authors recently for solving the deterministic mincut problem~\cite{LiP20}. We first describe this tool.
%
\BD[Minimum isolating cuts]
Consider a weighted, undirected graph $G=(V,E)$ and a subset $R\s V$ ($|R|\ge2$). The \emph{minimum isolating cuts} for $R$ is a collection of sets $\{S_v:v\in R\}$ such that for each vertex $v\in R$, the set $S_v$ satisfies $S_v\cap R=\{v\}$ and has the minimum value of $w(\pt S'_v)$ over all sets $S'_v$ satisfying $S'_v\cap R=\{v\}$.
\ED
%
%\alert{DP: In the above definition, should we also mention that sets $S_v$ must be disjoint? At the moment, this is in the next lemma. Would putting it in the definition might make life a bit easier in terms of just having to refer to the definition when invoking this property?}
%
\BL [Isolating Cuts Lemma~\cite{LiP20})]
Fix a subset $R\s V$ ($|R|\ge2$). There is an algorithm that computes the minimum isolating cuts $\{S_v:v\in R\}$ for $R$ using $O(\log|R|)$ calls to $s$--$t$ max-flow on weighted graphs of $O(n)$ vertices and $O(m)$ edges, and takes $\tO(m)$ deterministic time outside of the max-flow calls. If the original graph $G$ is unweighted, then the inputs to the max-flow calls are also unweighted. Moreover, the sets $\{S_v:v\in R\}$ are disjoint.
\EL
%
The crucial aspect of the isolating cuts lemma is that the number of maxflow calls is $O(\log n)$ {\em irrespective of the size of $R$}. For the \ct problem, define $Z= V\setminus \{s\}$; our goal is to invoke the isolating cuts lemma $\polylog(n)$ times and identify all vertices $v\in Z$ with $\mincut(s, v)\le \lambda$ whp. In fact, we will only describe an algorithm that identifies each vertex in $Z$ satisfying this condition with probability $\Omega(1/\polylog(n))$; removing these vertices from $Z$ and repeating $O(\log n)$ times identifies all such vertices in $Z$ whp. Fix a GH tree $T$ of the graph rooted at $s$, and let $(u, v)$ be an edge of weight $\le \lambda$ in $T$ where $u$ is closer to $s$ than $v$. Let $T_v$ denote the subtree under $v$ in $T$, and let $n_v$ be the number of vertices in $Z$ that appear in $T_v$. For any vertex $z\in T_v$, we have $\mincut(s, z) \le \lambda$. Now, suppose we sample a set of vertices from $Z$ at rate $1/n_v$ and define this sample as $R$. Then, we invoke the isolating cuts lemma with the set $R$, after adding $s$ to this set. Next, if the isolating cuts lemma returns cuts of value $\le \lambda$, we mark the vertices in $Z$ separated by those cuts from $s$ as having $\mincut(s, z)\le \lambda$ and remove them from $Z$. Clearly, every marked vertex $z$ indeed has $\min(s, z)\le \lambda$. But, how many vertices do we end up marking? Let us focus on the subtree $T_v$. With constant probability, exactly one vertex from $T_v$ is sampled in $R$, and with probability $\Omega(1/n_v)$, this sampled vertex is $v$ itself. In that happens, the isolating cut lemma would return the $s-v$ mincut, namely the cut represented by the edge $(u, v)$ in the GH tree. This allows us to mark all the $n_v$ vertices that are in $Z$ and appear in $T_v$. So, roughly speaking, we are able to mark at least $n_v$ vertices with probability $1/n_v$ in this case. Of course, we do not know the value of $n_v$, but we try all sampling levels in inverse powers of $2$. We formalize and refine this argument to show that we can indeed mark every vertex $z\in Z$ with $\mincut(s, z) \le \lambda$ with probability at least $\Omega(1/\log n)$ using this algorithm.

We now use the \ct algorithm as a ``sieve'' to obtain an \ssc algorithm. We start with $\mincut(s, v)$ for all vertices $v\in V\setminus \{s\}$ tentatively set to the maximum possible edge connectivity (call it $\lambda_{\max}$). Next, we run the \ct algorithm with $\lambda = (1-\e) \lambda_{\max}$. The vertices $v$ that are identified by this algorithm as having $\mincut(s, v) \le \lambda$ drop down to the next level of the hierarchy, while the remaining vertices $v'$ are declared to have $\mincut(s, v') \in ((1-\e)\lambda, \lambda]$. In the next level of the hierarchy, we again invoke the \ct algorithm, but now with $\lambda$ equal to $(1-\e)$ factor of the previous iteration. In this manner, we iteratively continue moving down the hierarchy, cutting the threshold $\lambda$ by a factor of $(1-\e)$ in every step, until the connectivity of all vertices has been determined.

Finally, we come to the problem of obtaining an approximate GH tree. Gomory and Hu's original algorithm uses the following strategy: find an $s-t$ mincut for any pair of vertices $s$ and $t$, and recurse on the two sides of the cut in separate subproblems where the other side of the cut is contracted to a single vertex. They used submodularity of cuts to show that contracting one side of an $s-t$ mincut does not change the connectivity between vertices on the other side. Moreover, they gave a procedure for combining the two GH trees returned by the recursive calls into a single GH tree at the end of the recursion. Ideally, we would like to use the same algorithm but replace an exact $s-t$ mincut with an approximate one. But now, the connectivities in the recursive subproblems are (additively) distorted by the approximation error of the $s-t$ mincut. This imposes two additional restrictions. {\bf (a)} First, the values of the $s-t$ mincuts identified in the recursive algorithm must now be monotone non-decreasing with depth of the recursion so that the approximation error on a larger $s-t$ mincut doesn't get propagated to a smaller $s'-t'$ mincut further down in the recursion. {\bf (b)} Second, the depth of recursion must now be $\polylog(n)$ so that one can control the buildup of approximation error in the recursion by setting the error parameter in a single step to be $\e/\polylog(n)$. Unfortunately, neither of these conditions is met by Gomory and Hu's algorithm. For instance, the recursion depth can be $n-1$ if each $s-t$ mincut is a degree cut. The order of $s-t$ mincut values in the recursion is also arbitrary and depends on the choice of $s$ and $t$ in each step (which itself is arbitrary).

Let us first consider condition {\bf (a)}. Instead of finding the $s-t$ mincut for an arbitrary pair of terminal vertices $s$ and $t$, suppose we found the Steiner mincut on the terminals, i.e., the cut of smallest value that splits the terminals. This would also suffice in terms of the framework since a Steiner mincut is also an $s-t$ mincut for some pair $s, t$. But, it brings additional advantages: namely, we get the monotonicity in cut values with recursive depth that we desire. At a high level, this is the idea that we implement: we use the \ct algorithm (with some technical modifications) where we set the threshold $\lambda$ to the value of the Steiner mincut, and identify a partitioning of the terminals where each subset of the partition represents a $(1+\e)$ approximation to the Steiner mincut. 

But, how do we achieve condition {\bf (b)}? Fixing the vertex $s$ in the invocation of the \ssc algorithm, we can identify terminal vertices $v$ that have $\mincut(s, v)\in ((1-\e)\lambda, \lambda]$, where $\lambda$ is the Steiner mincut. But, these approximate Steiner mincuts might be unbalanced in terms of the number of vertices on the two sides of the cut. To understand the problem, suppose there is a single Steiner mincut identified by the \ct algorithm, and this cut is the degree cut of $s$. Then, one subproblem contains all but one vertex in the next round of recursion; consequently, the recursive depth can be high. We overcome this difficulty in two steps. First, we ensure that the only ``large'' subproblem that we recurse on is the one that contains $s$. This can be ensured by sampling $O(\log n)$ different vertices as $s$, which boosts the probability that $s$ is on the larger side of an unbalanced approximate Steiner mincut. This ensures that in the recursion tree, we can only have a large recursive depth along the path containing $s$. Next, we show that even though we are using an approximate method for detemining mincuts, the approximation error only distorts the connectivities in the subproblems not containing $s$. This ensures that the approximation errors can build up only along paths in the recursion tree that have depth $O(\log n)$. Combining these two techniques, we obtain our overall algorithm for an approximate GH tree.